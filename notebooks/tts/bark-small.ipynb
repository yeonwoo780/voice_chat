{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mathai/voice_chat'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"../../\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mathai/miniforge3/envs/audio_chat/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/mathai/miniforge3/envs/audio_chat/lib/python3.10/site-packages/transformers/models/encodec/modeling_encodec.py:124: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer(\"padding_total\", torch.tensor(kernel_size - stride, dtype=torch.int64), persistent=False)\n",
      "The class `optimum.bettertransformers.transformation.BetterTransformer` is deprecated and will be removed in a future release.\n",
      "The BetterTransformer implementation does not support padding during training, as the fused kernels do not support attention masks. Beware that passing padded batched data during training may result in unexpected outputs. Please refer to https://huggingface.co/docs/optimum/bettertransformer/overview for more details.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoProcessor, AutoModel\n",
    "from IPython.display import Audio\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "processor = AutoProcessor.from_pretrained(\"suno/bark-small\")\n",
    "model = AutoModel.from_pretrained(\"suno/bark-small\").to(device)\n",
    "model =  model.to_bettertransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    }
   ],
   "source": [
    "inputs = processor(\n",
    "    text=[\"안녕하세요, 이 모델은 tts를 test하기 위한 모델 입니다.\"],\n",
    "    return_tensors=\"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "speech_values = model.generate(**inputs, do_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "import scipy\n",
    "\n",
    "sampling_rate = model.generation_config.sample_rate\n",
    "# Audio(speech_values.cpu().numpy().squeeze(), rate=sampling_rate)\n",
    "scipy.io.wavfile.write(\"bark_out_small.wav\", rate=sampling_rate, data=speech_values.cpu().numpy().squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, AutoModel\n",
    "from IPython.display import Audio\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"suno/bark\")\n",
    "model = AutoModel.from_pretrained(\"suno/bark\")\n",
    "model.to(\"cuda\")\n",
    "inputs = processor(\n",
    "    # \"안녕하세요, 이 모델은 tts를 test하기 위한 모델 입니다.\"\n",
    "    text=[\"こんにちは、このモデルはttsをテストするためのモデルです。\"],\n",
    "    return_tensors=\"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "speech_values = model.generate(**inputs, do_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "import scipy\n",
    "\n",
    "sampling_rate = model.generation_config.sample_rate\n",
    "# Audio(speech_values.cpu().numpy().squeeze(), rate=sampling_rate)\n",
    "scipy.io.wavfile.write(\"bark_out_jap.wav\", rate=sampling_rate, data=speech_values.cpu().numpy().squeeze())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio_chat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
